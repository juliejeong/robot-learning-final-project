{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "class FlappyBirdMultiAgentRL:\n",
    "    def __init__(self, num_agents=3, learning_rate=0.001, discount_factor=0.99):\n",
    "        self.env = gym.make('FlappyBird-v0')\n",
    "        self.num_agents = num_agents\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "        # Initialize neural networks for each agent\n",
    "        self.agents = [self._build_network() for _ in range(num_agents)]\n",
    "        self.optimizers = [optim.Adam(agent.parameters(), lr=learning_rate) for agent in self.agents]\n",
    "    \n",
    "    def _build_network(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(4, 64),  # Assuming 4 input features (bird pos, pipe positions)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # Output: actions (flap or not)\n",
    "        )\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        actions = []\n",
    "        for agent in self.agents:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.FloatTensor(state)\n",
    "                action_probs = torch.softmax(agent(state_tensor), dim=0)\n",
    "                action = torch.multinomial(action_probs, 1).item()\n",
    "                actions.append(action)\n",
    "        \n",
    "        # Collective decision making: majority vote\n",
    "        return max(set(actions), key=actions.count)\n",
    "    \n",
    "    def train(self, episodes=1000):\n",
    "        for episode in range(episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward, done, _, _ = self.env.step(action)\n",
    "                \n",
    "                # Cooperative reward adjustment\n",
    "                cooperative_reward = reward + (5 if not done else -100000)\n",
    "                \n",
    "                # Update each agent\n",
    "                for i, agent in enumerate(self.agents):\n",
    "                    self._update_agent(agent, self.optimizers[i], state, action, cooperative_reward, next_state, done)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += cooperative_reward\n",
    "            \n",
    "            if episode % 50 == 0:\n",
    "                print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "    \n",
    "    def _update_agent(self, agent, optimizer, state, action, reward, next_state, done):\n",
    "        # Standard Q-learning update\n",
    "        state_tensor = torch.FloatTensor(state)\n",
    "        next_state_tensor = torch.FloatTensor(next_state)\n",
    "        \n",
    "        current_q = agent(state_tensor)[action]\n",
    "        next_max_q = torch.max(agent(next_state_tensor)) if not done else 0\n",
    "        \n",
    "        target_q = reward + self.discount_factor * next_max_q\n",
    "        loss = nn.MSELoss()(current_q, torch.tensor(target_q))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    multi_agent_trainer = FlappyBirdMultiAgentRL(\n",
    "        num_agents=3, \n",
    "        learning_rate=0.001, \n",
    "        discount_factor=0.99\n",
    "    )\n",
    "    \n",
    "    multi_agent_trainer.train(episodes=1000)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
